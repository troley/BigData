{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RDD functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For processing (key, value) RDDs, there are a few functions that simplify common flow patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to the map() transformation, **mapValues( f( v -> v' ) )** can only be used on (key, value) pairs. It applies a function f to map a value v to v', and results in (key, v') pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numbers = sc.parallelize([('John' ,3), ('Peter' ,8), ('Peter', 10), ('Mike', 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numbers.mapValues(lambda x: x + 1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When mapping an RDD of N-elements, this will always result in an RDD of exactly N-elements, since every element will be transformed into exactly one value. When we want to map an element to zero or more elements, the default approach is starts with mapping every result to a list, lists that can contain zero or more elements. An RDD of lists can be **flatten**ed to an RDD of the elements that are contained in the lists, using the **flatten** transformation function. \n",
    "\n",
    "Consider the case where we want to process all the words in a textfile. Initially, the *textfile()* method will create an element for every line. Some lines are empty (contain no words), but most lines contain multiple words. To transform the lines to words we can first map each line to a list of words using Python's **split()** function, and then flatten the result to obtain an RDD of words.\n",
    "\n",
    "Let us first consider a small in-memory example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = sc.parallelize([\"This is line 1\", \"\", \n",
    "                        \"This is line two\", \"Three\", \n",
    "                        \"This is the last line\"])\n",
    "lists = lines.map(lambda x: x.split())\n",
    "print(lists.count(), lists.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RDD lists contains 5 elements, 5 lists of 0 or more words. To flatten the RDD, you will notice that Spark actually has no **flatten** transformation, but there is a **flatMap()** transformation instead. Presumably, since flattening is a relatively expensive operation and combining a flatten with a map relatively inexpensive, the absence of a flatten transformation may make programmers more conscious about always combining a map with a flatten. In any case, we can use **flatMap(lambda x:x)** with a so called identity function, to just flatten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = lists.flatMap(lambda x:x)\n",
    "print(words.count(), words.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For educational purposes, it is good to see how the lines are mapped to lists and then how the RDD is flattened. However, this flow is commonly written in one operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words2 = lines.flatMap(lambda x: x.split())\n",
    "print(words2.count(), words2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to realize that flatten will only remove **one nested level**. To show what happens, we force a scenario in which an RDD in which the elements are lists with both words and nested lists in them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foolists = lines.map(lambda x: ['Foo', x.split()])\n",
    "print(foolists.count(), foolists.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe carefully, the most outer [] represent the RDD. Within the RDD, the first element is `['Foo', ['This', 'is', 'line', '1']]`, which contains a word and a list. Flattening the result will remove the list surrounding the element, so that two new elements are the result: `'Foo'` and `['This', 'is', 'line', '1']`. The empty list that is embedded in another list does not simply vanish. Therefore the result is 10 elements, 2 elements for every line. Note that mixtures of lists and non-lists are rarely used in Spark, because it makes processing more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foowords = foolists.flatMap(lambda x:x)\n",
    "print(foowords.count(), foowords.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flatMapValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a combined transformation **flatMapValues(f)** which is equivalent to a `mapValues(f)` followed by `mapFlat(i)` where i is the identify function. Flattening of (key, value) pairs causes the mapped values to remain bound to the original keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kv = sc.parallelize([(1, \"This is line 1\"), \n",
    "                     (2, \"\"), \n",
    "                     (3, \"This is line two\"),\n",
    "                     (4, \"Three\"), \n",
    "                     (5, \"This is the last line\") ])\n",
    "letters = kv.flatMapValues(lambda x: x.split())\n",
    "print(letters.count(), letters.collect())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
