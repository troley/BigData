{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom function to read a flat text file into Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets setup an RDD to process the babyname data. We can use what we have learned previously to create a function that sets up an RDD for a multi-column flat text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../data/babynames.csv'\n",
    "if not os.path.exists(filename):\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve (\"https://health.data.ny.gov/api/views/jxy9-yhdk/rows.csv?accessType=DOWNLOAD\", \\\n",
    "                                filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readCSV(fname, header=False, separator=','):\n",
    "    rdd = sc.textFile(fname)\n",
    "    if header:\n",
    "        firstline = rdd.first()\n",
    "        rdd = rdd.filter(lambda x: x != firstline)\n",
    "    return rdd.map(lambda x: x.split(separator))\n",
    "\n",
    "babyrdd = readCSV(filename, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2013', 'GAVIN', 'ST LAWRENCE', 'M', '9']\n"
     ]
    }
   ],
   "source": [
    "print(babyrdd.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply count the number of elements in an RDD using the action **count**. Note that since count is an action, the RDD is executed and the result is a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52252\n"
     ]
    }
   ],
   "source": [
    "print(babyrdd.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can count how many Male and Female records there are in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27622\n",
      "24630\n"
     ]
    }
   ],
   "source": [
    "print(babyrdd.filter(lambda x: x[3] == 'M').count())\n",
    "print(babyrdd.filter(lambda x: x[3] == 'F').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key-Value pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common **flow pattern** for distributed processing is the **Map-Reduce** pattern. (1) All elements in a dataset are first processed by a **map(e -> (k, v))** function, which consumes elements and results in **(key, value)** pairs. By protocol, the key-values identify which values go together, i.e. pairs that have the same key-value are considered values for the same key. (2) The (key, value) pairs that are produced by the map() function, are grouped by their key-values (often this is an implicit step, we do not have to specifically write instructions for this). (3) Per key-value, a **reduce( v1, v2 -> v )** function is called on two values `v1` and `v2`, and produces a single value `v` of the same type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReduceByKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the counts per gender in one flow, we wish to transform every element in the RDD into a (gender, count) pair. Initially we can simply transform every element into (gender, 1) and then sum the values per gender. The transformation **reduceByKey( v1, v2 -> v )** consumes two values `v1` and `v2` that belong to the same key and reduces it to a single value 'v' of the same type. Although reduce is an action, reduceByKey is a tranformation that results in a new RDD. We can use the **collect()** action to collect all results.\n",
    "\n",
    "Note: the values are unordered, and therefore the function must be *commutative*, i.e. produce the same result regardless of the order of the operands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', 1), ('M', 1), ('M', 1), ('M', 1), ('M', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv = babyrdd.map(lambda x: (x[3], 1))\n",
    "kv.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', 27622), ('F', 24630)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv.reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CollectAsMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with (key, value) pairs, it can be easier to retrieve the results as a Python dict object. In Scala (the langauge in which Spark was written), the equivalent of a dict is a Map, hence the action name **collectAsMap()** to collect the results as a dictionary of key-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27622, 24630)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = kv.reduceByKey(lambda x, y: x + y).collectAsMap()\n",
    "(d['M'], d['F'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also lookup which values are associated with a single key, by using the **lookup(key)** action. Lookup will return a list of values (even if there is None or one), beacuse keys may not exist and keys are not required to be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27622]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv.reduceByKey(lambda x, y: x + y).lookup('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AggregateByKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more control, we can use the **aggregateByKey(zero() -> r, f1(r, v) -> r, f2(r1, r2) -> r)**. In contrast to reduceByKey, the aggregation transformation (a.k.a. fold) accumulates a result that can be of a different type than the values. Initially, the **zero()** function is called to generate an initial accumulator (often zero or empty). Then for every value, f1 is called to add a value to the accumulator. Note that because we are working with distributed data, multiple aggregators will work in parallel each producing an accumulator as its reults. To merge these partial results of two aggregators, a final function f2 is called to merge two accumulators.\n",
    "\n",
    "In the example below, we initialize the count per gender as 0. Then for every (key, value) pair, the second function adds the value to the accumulator. Finally, if there are multiple nodes that are used in parallel on the same key, their results can be added using the final function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', 27622), ('F', 24630)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv.aggregateByKey(\\\n",
    "                  0, # initial value for an accumulator \\\n",
    "                  lambda r, v: r + v, # function that adds a value to an accumulator \\\n",
    "                  lambda r1, r2: r1 + r2 # function that merges/combines two accumulators \\\n",
    "                 ).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To count the number of distinctly different names, we can use aggregateByKey to have more control over the reduce function. First we will look at Python sets to see how we can work with sets to obtain a proper count. We can create a set using the **set()** constructor, and add elements using **add()**. By definition, a set contains only unique elements, thus adding a value that already exists results in no change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mike', 'Peter'} size: 2\n"
     ]
    }
   ],
   "source": [
    "s = set(['Peter'])\n",
    "s.add('Mike')\n",
    "s.add('Peter')\n",
    "print(s, 'size:', len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can union two sets using the **union()** method, resulting in a set that contains all elements in either set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'James', 'Mike', 'Peter'} size: 3\n"
     ]
    }
   ],
   "source": [
    "t = set(['Peter', 'James'])\n",
    "u = s.union(t)\n",
    "print(u, 'size:', len(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then accumulate the names in a set to find the number of unique names per gender. First, we need to setup an RDD that contains (gender, name) pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('M', 'GAVIN'), ('M', 'LEVI'), ('M', 'LOGAN'), ('M', 'HUDSON'), ('M', 'GABRIEL')]\n"
     ]
    }
   ],
   "source": [
    "gendernames = babyrdd.map(lambda x: (x[3], x[1]))\n",
    "print(gendernames.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since the *add* function does not return a value, we need a function to first add a name and then return the set of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def addToSet(names, name):\n",
    "    names.add(name)\n",
    "    return names\n",
    "\n",
    "r = gendernames.aggregateByKey(\\\n",
    "                               set(), # initial value for an accumulator \\\n",
    "                               addToSet, # function to add a value to an accumulator \\\n",
    "                               lambda r1, r2: r1.union(r2) # function to merge two accumulators \\\n",
    "                              )\n",
    "print(r.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a good look at the structure of the RDD. The contents of the RDD is printed within []. Evert element of the RDD is a tuple (in this case a key-value pair), which is printed within (). Within the key-value pairs for the keys 'M' and 'F', the values are sets which are printed with {}. Note that in many languages (e.g. Python, Java), a set is just a dictionary without values. \n",
    "\n",
    "Since every element x is a (key, value) pair, we can address the key as x[0] and the value as x[1]. Then we can count the number of unique names per gender as the length of their sets of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', 984), ('F', 1182)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.map(lambda x: (x[0], len(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CombineByKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **CombineByKey( init(v) -> acc, f1(acc, v) -> acc, f2(acc, acc) -> acc )** tranformation function is similar to aggregateByKey, except that instead of a zero function an initializer function **init** is used on the first value to setup an accumulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', 984), ('F', 1182)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gendernames.combineByKey(\\\n",
    "                               lambda x: set([x]), # initial value for an accumulator \\\n",
    "                               addToSet, # function to add a value to an accumulator \\\n",
    "                               lambda r1, r2: r1.union(r2) # function to merge two accumulators \\\n",
    "                              ).map(lambda x: (x[0], len(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## groupByKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **groupByKey()** transformation groups all values for the same key into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', <pyspark.resultiterable.ResultIterable at 0x1b3b5a4d550>),\n",
       " ('F', <pyspark.resultiterable.ResultIterable at 0x1b3b5a4d668>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gendernames.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result are iterables, which are evaluated when needed. In this example, the Python function `Counter` counts how often every element appears in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "gendernames.groupByKey().mapValues(lambda x: Counter(x)).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SubtractByKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an RDD of (key, value) elements we can remove the keys that exist in another RDD using the **subtractByKey(r)** transformation. This transformationthe *not in* operator in SQL.\n",
    "\n",
    "First, construct an RDD with (name, gender) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GAVIN', 'M'), ('LEVI', 'M')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameGenders = babyrdd.map(lambda x: (x[1], x[3]))\n",
    "nameGenders.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then group the pairs by name, count the number of different genders by the length of a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ADRIEN', 1), ('HERSH', 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameCountGenders = nameGenders.groupByKey().mapValues(lambda x: len(set(x)))\n",
    "nameCountGenders.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And keep only names that are used for one gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ADRIEN', 1), ('HERSH', 1)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameSingleGender = nameCountGenders.filter(lambda x: x[1] < 2)\n",
    "nameSingleGender.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now show only the names that do are not used for a single gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subtractByKey' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-7cf5674c6816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnameGenders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtractByKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnameSingleGender\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubtractByKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'subtractByKey' is not defined"
     ]
    }
   ],
   "source": [
    "nameGenders.subtractByKey(nameSingleGender).keys().distinct().tak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keys and Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an RDD of (key, value) elements, we can use only the keys using the **keys()** transformation and use only the values using the **values()** transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gendernames.keys().take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gendernames.values().take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
